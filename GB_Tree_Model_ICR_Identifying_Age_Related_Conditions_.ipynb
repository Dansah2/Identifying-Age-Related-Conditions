{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dansah2/Identifying-Age-Related-Conditions/blob/main/GB_Tree_Model_ICR_Identifying_Age_Related_Conditions_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWrKiQ4fRGS"
      },
      "source": [
        "# ICR - Identifying Age-Related Conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6F6FaOB0dQ"
      },
      "source": [
        "Kaggle Dataset Download API Command:\n",
        "\n",
        "kaggle competitions download -c icr-identify-age-related-conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXlEc616CFtt"
      },
      "source": [
        "Predict whether a subject has or has not been diagnosed with one of these conditions -- a binary classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEHxmjhghVvK"
      },
      "source": [
        "##Project Outline:\n",
        "\n",
        "1) Download the dataset\n",
        "\n",
        "2) Explore/Analyze the data\n",
        "\n",
        "3) Preprocess and organize the data\n",
        "\n",
        "4) Create and Train baseline Model\n",
        "\n",
        "5) Save the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdmA7kIfkiE"
      },
      "source": [
        "## Download the Dataset\n",
        "\n",
        "1) Install required libraries\n",
        "\n",
        "2) Import required libraries\n",
        "\n",
        "3) Obtain the preprocessed data previously saved to Google Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khuyKRt5FkpA"
      },
      "source": [
        "#### Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n",
        "!pip install -q -U scikit-learn\n",
        "!pip install -q -U numpy\n",
        "!pip install -q -U tensorflow_decision_forests\n",
        "!pip install -q -U plotly"
      ],
      "metadata": {
        "id": "UtRLXXUXfqMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ed970f-765a-4458-d5a9-c7be8a39e91b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.0 which is incompatible.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ylR8aSxIbKf"
      },
      "source": [
        "#### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and handeling data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# model training\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "# downloading data\n",
        "from google.colab import drive\n",
        "\n",
        "# Training the model with k-fold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# hyperparameter tuning\n",
        "import keras_tuner as kt\n",
        "\n",
        "# graph training accuracy and loss\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots"
      ],
      "metadata": {
        "id": "QVtrLcfxftWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100959c4-9c06-46d7-b706-ebfd6cc94c76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3N4YRGJIrmz"
      },
      "source": [
        "#### Obtain the preprocessed data previously saved to Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbeUxY8jQlaw",
        "outputId": "598caec6-a5d2-466f-a4c1-25f465606fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive to store Kaggle API for future use\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L5JLtC0lF8_I"
      },
      "outputs": [],
      "source": [
        "# create a function to read the data into a dataframe\n",
        "\n",
        "def read_function(csv_file):\n",
        "\n",
        "    return pd.read_csv(csv_file)\n",
        "\n",
        "clean_train = read_function('/content/drive/My Drive/ICR_Project/encoded_train_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Train baseline model\n",
        "1) Calculate the weights\n",
        "\n",
        "2) Create the model / callbacks\n",
        "\n",
        "3) Define the plot function\n",
        "\n",
        "4) Train the model"
      ],
      "metadata": {
        "id": "59kg4f6bjH4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Calculate the weights"
      ],
      "metadata": {
        "id": "d8duJCIok9o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights(train_df, target):\n",
        "  # Calculate the number of samples for each label.\n",
        "  neg, pos = np.bincount(train_df[target])\n",
        "\n",
        "  # Calculate total samples.\n",
        "  total = neg + pos\n",
        "\n",
        "  # Calculate the weight for each label.\n",
        "  weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "  weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "  class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "  print(f'Weight for class 0: {weight_for_0:.2f}')\n",
        "  print(f'Weight for class 1: {weight_for_1:.2f}')\n",
        "\n",
        "  return class_weight\n",
        "\n",
        "class_weight = get_weights(clean_train, 'Class')"
      ],
      "metadata": {
        "id": "tcFrsdGDjIye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c579a746-03b3-4cb1-fbeb-860281903961"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for class 0: 0.61\n",
            "Weight for class 1: 2.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Select the model"
      ],
      "metadata": {
        "id": "9q_qRRgMjKyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the models to select from\n",
        "tfdf.keras.get_all_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcFKzlgAcVj7",
        "outputId": "8dfa06f5-4295-437b-c881-46e6758d3625"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensorflow_decision_forests.keras.RandomForestModel,\n",
              " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
              " tensorflow_decision_forests.keras.CartModel,\n",
              " tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check config options\n",
        "model = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqgVsb3zcXoQ",
        "outputId": "30f48bb2-6215-40e4-d8f5-4532dfd431d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolve hyper-parameter template \"benchmark_rank1\" to \"benchmark_rank1@v1\" -> {'growing_strategy': 'BEST_FIRST_GLOBAL', 'categorical_algorithm': 'RANDOM', 'split_axis': 'SPARSE_OBLIQUE', 'sparse_oblique_normalization': 'MIN_MAX', 'sparse_oblique_num_projections_exponent': 1.0}.\n",
            "Use /tmp/tmp_8gfyu2k as temporary training directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tune hyperparameters\n"
      ],
      "metadata": {
        "id": "E8eqqT8ZfuJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(clean_train, label=\"Class\")\n",
        "\n",
        "tuner = tfdf.tuner.RandomSearch(num_trials=20)\n",
        "\n",
        "# Hyper-parameters to optimize.\n",
        "tuner.choice(\"max_depth\", [3, 4, 5, 6, 7, 8, 9, 10])\n",
        "tuner.choice(\"num_trees\", [400, 500, 600, 700, 800])\n",
        "\n",
        "model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
        "model.fit(tf_dataset)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi6ClFBYub0B",
        "outputId": "4b24d0b4-63fa-4955-bb75-34d9fee14ae3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp8dr9c49d as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:07.934735. Found 617 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:08.404447\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x79e142a5d1b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x79e142a5d1b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n",
            "Model: \"gradient_boosted_trees_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (57):\n",
            "\tAB\n",
            "\tAF\n",
            "\tAH\n",
            "\tAM\n",
            "\tAR\n",
            "\tAX\n",
            "\tAY\n",
            "\tAZ\n",
            "\tBC\n",
            "\tBD_\n",
            "\tBN\n",
            "\tBP\n",
            "\tBQ\n",
            "\tBR\n",
            "\tBZ\n",
            "\tCB\n",
            "\tCC\n",
            "\tCD_\n",
            "\tCF\n",
            "\tCH\n",
            "\tCL\n",
            "\tCR\n",
            "\tCS\n",
            "\tCU\n",
            "\tCW_\n",
            "\tDA\n",
            "\tDE\n",
            "\tDF\n",
            "\tDH\n",
            "\tDI\n",
            "\tDL\n",
            "\tDN\n",
            "\tDU\n",
            "\tDV\n",
            "\tDY\n",
            "\tEB\n",
            "\tEE\n",
            "\tEG\n",
            "\tEH\n",
            "\tEJ_A\n",
            "\tEJ_B\n",
            "\tEL\n",
            "\tEP\n",
            "\tEU\n",
            "\tFC\n",
            "\tFD_\n",
            "\tFE\n",
            "\tFI\n",
            "\tFL\n",
            "\tFR\n",
            "\tFS\n",
            "\tGB\n",
            "\tGE\n",
            "\tGF\n",
            "\tGH\n",
            "\tGI\n",
            "\tGL\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.  \"DU\"  0.399590 ################\n",
            "    2.  \"CC\"  0.364146 ######\n",
            "    3.  \"BQ\"  0.360777 #####\n",
            "    4.  \"GL\"  0.358786 #####\n",
            "    5.  \"FR\"  0.356002 ####\n",
            "    6.  \"AB\"  0.349776 ##\n",
            "    7.  \"CH\"  0.349306 ##\n",
            "    8.  \"EH\"  0.348681 ##\n",
            "    9.  \"EL\"  0.348370 ##\n",
            "   10.  \"CR\"  0.347904 ##\n",
            "   11.  \"DL\"  0.347904 ##\n",
            "   12.  \"CS\"  0.347439 ##\n",
            "   13.  \"FE\"  0.346975 ##\n",
            "   14.  \"DA\"  0.346667 ##\n",
            "   15.  \"EU\"  0.346205 ##\n",
            "   16.  \"DE\"  0.345591 #\n",
            "   17. \"CD_\"  0.344828 #\n",
            "   18.  \"EB\"  0.344675 #\n",
            "   19.  \"CU\"  0.344523 #\n",
            "   20.  \"BR\"  0.344371 #\n",
            "   21.  \"AF\"  0.344219 #\n",
            "   22.  \"FL\"  0.344219 #\n",
            "   23.  \"DH\"  0.343764 #\n",
            "   24.  \"BC\"  0.342556 #\n",
            "   25.  \"EE\"  0.342406 #\n",
            "   26.  \"AH\"  0.341955 \n",
            "   27.  \"AX\"  0.341955 \n",
            "   28.  \"AY\"  0.341506 \n",
            "   29.  \"EG\"  0.341506 \n",
            "   30.  \"DI\"  0.340611 \n",
            "   31.  \"DY\"  0.340611 \n",
            "   32.  \"DN\"  0.340166 \n",
            "   33.  \"FI\"  0.340166 \n",
            "   34.  \"CL\"  0.339721 \n",
            "   35.  \"GH\"  0.339721 \n",
            "   36.  \"AM\"  0.339278 \n",
            "   37.  \"DF\"  0.339278 \n",
            "   38.  \"DV\"  0.339278 \n",
            "   39.  \"EP\"  0.339278 \n",
            "   40.  \"BP\"  0.338836 \n",
            "   41.  \"CB\"  0.338836 \n",
            "   42.  \"FS\"  0.338836 \n",
            "   43.  \"AR\"  0.338395 \n",
            "   44.  \"BN\"  0.338395 \n",
            "   45.  \"CF\"  0.338395 \n",
            "   46.  \"FC\"  0.338395 \n",
            "   47. \"FD_\"  0.338395 \n",
            "   48.  \"GB\"  0.338395 \n",
            "   49.  \"GE\"  0.338395 \n",
            "   50.  \"GI\"  0.338395 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.  \"DU\" 26.000000 ################\n",
            "    2.  \"CC\" 14.000000 ########\n",
            "    3.  \"BQ\" 11.000000 ######\n",
            "    4.  \"GL\" 11.000000 ######\n",
            "    5.  \"FR\"  7.000000 ###\n",
            "    6.  \"CH\"  6.000000 ###\n",
            "    7.  \"CS\"  5.000000 ##\n",
            "    8.  \"EL\"  5.000000 ##\n",
            "    9.  \"DA\"  4.000000 #\n",
            "   10.  \"DL\"  4.000000 #\n",
            "   11.  \"EH\"  4.000000 #\n",
            "   12.  \"EU\"  4.000000 #\n",
            "   13.  \"FE\"  4.000000 #\n",
            "   14.  \"AF\"  3.000000 #\n",
            "   15. \"CD_\"  3.000000 #\n",
            "   16.  \"CR\"  3.000000 #\n",
            "   17.  \"EB\"  3.000000 #\n",
            "   18.  \"AY\"  2.000000 \n",
            "   19.  \"BR\"  2.000000 \n",
            "   20.  \"CU\"  2.000000 \n",
            "   21.  \"DH\"  2.000000 \n",
            "   22.  \"AH\"  1.000000 \n",
            "   23.  \"BC\"  1.000000 \n",
            "   24.  \"DE\"  1.000000 \n",
            "   25.  \"DI\"  1.000000 \n",
            "   26.  \"FL\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.  \"DU\" 40.000000 ################\n",
            "    2.  \"AB\" 26.000000 ##########\n",
            "    3.  \"FR\" 18.000000 ######\n",
            "    4.  \"CC\" 17.000000 ######\n",
            "    5.  \"BQ\" 15.000000 #####\n",
            "    6.  \"EH\" 15.000000 #####\n",
            "    7.  \"DE\" 14.000000 #####\n",
            "    8.  \"GL\" 14.000000 #####\n",
            "    9.  \"CR\" 13.000000 ####\n",
            "   10.  \"FL\" 11.000000 ####\n",
            "   11.  \"CU\" 10.000000 ###\n",
            "   12.  \"DL\" 10.000000 ###\n",
            "   13.  \"EE\" 10.000000 ###\n",
            "   14.  \"AX\"  9.000000 ###\n",
            "   15.  \"EL\"  9.000000 ###\n",
            "   16.  \"BC\"  8.000000 ##\n",
            "   17.  \"EG\"  8.000000 ##\n",
            "   18.  \"FE\"  8.000000 ##\n",
            "   19.  \"BR\"  7.000000 ##\n",
            "   20.  \"CH\"  7.000000 ##\n",
            "   21.  \"DA\"  7.000000 ##\n",
            "   22.  \"DH\"  7.000000 ##\n",
            "   23.  \"EU\"  7.000000 ##\n",
            "   24.  \"AH\"  6.000000 ##\n",
            "   25. \"CD_\"  6.000000 ##\n",
            "   26.  \"CS\"  6.000000 ##\n",
            "   27.  \"DY\"  6.000000 ##\n",
            "   28.  \"EB\"  6.000000 ##\n",
            "   29.  \"AF\"  5.000000 #\n",
            "   30.  \"DN\"  5.000000 #\n",
            "   31.  \"FI\"  5.000000 #\n",
            "   32.  \"CL\"  4.000000 #\n",
            "   33.  \"GH\"  4.000000 #\n",
            "   34.  \"AM\"  3.000000 \n",
            "   35.  \"DF\"  3.000000 \n",
            "   36.  \"DI\"  3.000000 \n",
            "   37.  \"DV\"  3.000000 \n",
            "   38.  \"EP\"  3.000000 \n",
            "   39.  \"AY\"  2.000000 \n",
            "   40.  \"BP\"  2.000000 \n",
            "   41.  \"CB\"  2.000000 \n",
            "   42.  \"FS\"  2.000000 \n",
            "   43.  \"AR\"  1.000000 \n",
            "   44.  \"BN\"  1.000000 \n",
            "   45.  \"CF\"  1.000000 \n",
            "   46.  \"FC\"  1.000000 \n",
            "   47. \"FD_\"  1.000000 \n",
            "   48.  \"GB\"  1.000000 \n",
            "   49.  \"GE\"  1.000000 \n",
            "   50.  \"GI\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.  \"DU\" 104.083159 ################\n",
            "    2.  \"CR\" 35.177587 #####\n",
            "    3.  \"DA\" 23.319519 ###\n",
            "    4.  \"BC\" 20.128741 ###\n",
            "    5.  \"AB\" 20.077489 ###\n",
            "    6.  \"FR\" 18.691368 ##\n",
            "    7.  \"BQ\" 16.551942 ##\n",
            "    8.  \"GL\" 13.142975 ##\n",
            "    9.  \"EG\" 12.671529 #\n",
            "   10.  \"DE\" 11.542636 #\n",
            "   11.  \"DY\"  9.362400 #\n",
            "   12.  \"CC\"  8.530472 #\n",
            "   13.  \"FE\"  6.378534 \n",
            "   14.  \"DH\"  5.480423 \n",
            "   15.  \"DI\"  5.373887 \n",
            "   16.  \"EE\"  4.813573 \n",
            "   17.  \"DL\"  4.321073 \n",
            "   18.  \"FI\"  4.257493 \n",
            "   19.  \"EL\"  3.974721 \n",
            "   20.  \"CU\"  3.798582 \n",
            "   21.  \"BR\"  3.441306 \n",
            "   22.  \"AF\"  3.411499 \n",
            "   23.  \"AX\"  3.167292 \n",
            "   24.  \"EH\"  2.999477 \n",
            "   25.  \"FL\"  2.219052 \n",
            "   26.  \"EP\"  2.049662 \n",
            "   27.  \"BP\"  1.597715 \n",
            "   28.  \"EB\"  1.450828 \n",
            "   29.  \"CS\"  1.145624 \n",
            "   30.  \"CH\"  1.059090 \n",
            "   31.  \"EU\"  1.013129 \n",
            "   32.  \"AR\"  0.921151 \n",
            "   33.  \"GH\"  0.900963 \n",
            "   34.  \"DN\"  0.887159 \n",
            "   35.  \"AM\"  0.824771 \n",
            "   36.  \"AH\"  0.785410 \n",
            "   37.  \"DV\"  0.757409 \n",
            "   38.  \"CL\"  0.689592 \n",
            "   39.  \"DF\"  0.663315 \n",
            "   40.  \"CB\"  0.654942 \n",
            "   41. \"CD_\"  0.649877 \n",
            "   42.  \"FS\"  0.642484 \n",
            "   43.  \"GE\"  0.341816 \n",
            "   44.  \"AY\"  0.335883 \n",
            "   45. \"FD_\"  0.288806 \n",
            "   46.  \"CF\"  0.222348 \n",
            "   47.  \"BN\"  0.161344 \n",
            "   48.  \"FC\"  0.118714 \n",
            "   49.  \"GB\"  0.072381 \n",
            "   50.  \"GI\"  0.069095 \n",
            "\n",
            "\n",
            "Hyperparameter optimizer:\n",
            "\n",
            "Best parameters: max_depth:3 num_trees:700\n",
            "Num steps: 20\n",
            "Best score: -0.464162\n",
            "\n",
            "Step #0 score:-0.519939 parameters:{ max_depth:4 num_trees:800 }\n",
            "Step #1 score:-0.630248 parameters:{ max_depth:10 num_trees:500 }\n",
            "Step #2 score:-0.562768 parameters:{ max_depth:5 num_trees:600 }\n",
            "Step #3 score:-0.630248 parameters:{ max_depth:10 num_trees:800 }\n",
            "Step #4 score:-0.628445 parameters:{ max_depth:8 num_trees:800 }\n",
            "Step #5 score:-0.464162 parameters:{ max_depth:3 num_trees:700 }\n",
            "Step #6 score:-0.562768 parameters:{ max_depth:5 num_trees:400 }\n",
            "Step #7 score:-0.630248 parameters:{ max_depth:10 num_trees:600 }\n",
            "Step #8 score:-0.587805 parameters:{ max_depth:9 num_trees:500 }\n",
            "Step #9 score:-0.519939 parameters:{ max_depth:4 num_trees:700 }\n",
            "Step #10 score:-0.639956 parameters:{ max_depth:6 num_trees:700 }\n",
            "Step #11 score:-0.639956 parameters:{ max_depth:6 num_trees:600 }\n",
            "Step #12 score:-0.519939 parameters:{ max_depth:4 num_trees:500 }\n",
            "Step #13 score:-0.587805 parameters:{ max_depth:9 num_trees:400 }\n",
            "Step #14 score:-0.464162 parameters:{ max_depth:3 num_trees:400 }\n",
            "Step #15 score:-0.628445 parameters:{ max_depth:8 num_trees:400 }\n",
            "Step #16 score:-0.628445 parameters:{ max_depth:8 num_trees:700 }\n",
            "Step #17 score:-0.612557 parameters:{ max_depth:7 num_trees:800 }\n",
            "Step #18 score:-0.587805 parameters:{ max_depth:9 num_trees:800 }\n",
            "Step #19 score:-0.612557 parameters:{ max_depth:7 num_trees:700 }\n",
            "\n",
            "\n",
            "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
            "Validation loss value: 0.464162\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 130\n",
            "Total number of nodes: 878\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 130 Average: 6.75385 StdDev: 0.657051\n",
            "Min: 5 Max: 7 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 5, 6)  16  12.31%  12.31% #\n",
            "[ 6, 7)   0   0.00%  12.31%\n",
            "[ 7, 7] 114  87.69% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 504 Average: 1.96825 StdDev: 0.175323\n",
            "Min: 1 Max: 2 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)  16   3.17%   3.17%\n",
            "[ 2, 2] 488  96.83% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 504 Average: 144.444 StdDev: 163.629\n",
            "Min: 5 Max: 545 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  32) 185  36.71%  36.71% ##########\n",
            "[  32,  59)  68  13.49%  50.20% ####\n",
            "[  59,  86)  35   6.94%  57.14% ##\n",
            "[  86, 113)  27   5.36%  62.50% #\n",
            "[ 113, 140)  11   2.18%  64.68% #\n",
            "[ 140, 167)  23   4.56%  69.25% #\n",
            "[ 167, 194)  13   2.58%  71.83% #\n",
            "[ 194, 221)   8   1.59%  73.41%\n",
            "[ 221, 248)  11   2.18%  75.60% #\n",
            "[ 248, 275)   6   1.19%  76.79%\n",
            "[ 275, 302)   3   0.60%  77.38%\n",
            "[ 302, 329)   8   1.59%  78.97%\n",
            "[ 329, 356)  13   2.58%  81.55% #\n",
            "[ 356, 383)  15   2.98%  84.52% #\n",
            "[ 383, 410)  18   3.57%  88.10% #\n",
            "[ 410, 437)  18   3.57%  91.67% #\n",
            "[ 437, 464)   8   1.59%  93.25%\n",
            "[ 464, 491)  16   3.17%  96.43% #\n",
            "[ 491, 518)   9   1.79%  98.21%\n",
            "[ 518, 545]   9   1.79% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t40 : DU [NUMERICAL]\n",
            "\t26 : AB [NUMERICAL]\n",
            "\t18 : FR [NUMERICAL]\n",
            "\t17 : CC [NUMERICAL]\n",
            "\t15 : EH [NUMERICAL]\n",
            "\t15 : BQ [NUMERICAL]\n",
            "\t14 : GL [NUMERICAL]\n",
            "\t14 : DE [NUMERICAL]\n",
            "\t13 : CR [NUMERICAL]\n",
            "\t11 : FL [NUMERICAL]\n",
            "\t10 : EE [NUMERICAL]\n",
            "\t10 : DL [NUMERICAL]\n",
            "\t10 : CU [NUMERICAL]\n",
            "\t9 : EL [NUMERICAL]\n",
            "\t9 : AX [NUMERICAL]\n",
            "\t8 : FE [NUMERICAL]\n",
            "\t8 : EG [NUMERICAL]\n",
            "\t8 : BC [NUMERICAL]\n",
            "\t7 : EU [NUMERICAL]\n",
            "\t7 : DH [NUMERICAL]\n",
            "\t7 : DA [NUMERICAL]\n",
            "\t7 : CH [NUMERICAL]\n",
            "\t7 : BR [NUMERICAL]\n",
            "\t6 : EB [NUMERICAL]\n",
            "\t6 : DY [NUMERICAL]\n",
            "\t6 : CS [NUMERICAL]\n",
            "\t6 : CD_ [NUMERICAL]\n",
            "\t6 : AH [NUMERICAL]\n",
            "\t5 : FI [NUMERICAL]\n",
            "\t5 : DN [NUMERICAL]\n",
            "\t5 : AF [NUMERICAL]\n",
            "\t4 : GH [NUMERICAL]\n",
            "\t4 : CL [NUMERICAL]\n",
            "\t3 : EP [NUMERICAL]\n",
            "\t3 : DV [NUMERICAL]\n",
            "\t3 : DI [NUMERICAL]\n",
            "\t3 : DF [NUMERICAL]\n",
            "\t3 : AM [NUMERICAL]\n",
            "\t2 : FS [NUMERICAL]\n",
            "\t2 : CB [NUMERICAL]\n",
            "\t2 : BP [NUMERICAL]\n",
            "\t2 : AY [NUMERICAL]\n",
            "\t1 : GI [NUMERICAL]\n",
            "\t1 : GE [NUMERICAL]\n",
            "\t1 : GB [NUMERICAL]\n",
            "\t1 : FD_ [NUMERICAL]\n",
            "\t1 : FC [NUMERICAL]\n",
            "\t1 : CF [NUMERICAL]\n",
            "\t1 : BN [NUMERICAL]\n",
            "\t1 : AR [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t26 : DU [NUMERICAL]\n",
            "\t14 : CC [NUMERICAL]\n",
            "\t11 : GL [NUMERICAL]\n",
            "\t11 : BQ [NUMERICAL]\n",
            "\t7 : FR [NUMERICAL]\n",
            "\t6 : CH [NUMERICAL]\n",
            "\t5 : EL [NUMERICAL]\n",
            "\t5 : CS [NUMERICAL]\n",
            "\t4 : FE [NUMERICAL]\n",
            "\t4 : EU [NUMERICAL]\n",
            "\t4 : EH [NUMERICAL]\n",
            "\t4 : DL [NUMERICAL]\n",
            "\t4 : DA [NUMERICAL]\n",
            "\t3 : EB [NUMERICAL]\n",
            "\t3 : CR [NUMERICAL]\n",
            "\t3 : CD_ [NUMERICAL]\n",
            "\t3 : AF [NUMERICAL]\n",
            "\t2 : DH [NUMERICAL]\n",
            "\t2 : CU [NUMERICAL]\n",
            "\t2 : BR [NUMERICAL]\n",
            "\t2 : AY [NUMERICAL]\n",
            "\t1 : FL [NUMERICAL]\n",
            "\t1 : DI [NUMERICAL]\n",
            "\t1 : DE [NUMERICAL]\n",
            "\t1 : BC [NUMERICAL]\n",
            "\t1 : AH [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t40 : DU [NUMERICAL]\n",
            "\t26 : AB [NUMERICAL]\n",
            "\t18 : FR [NUMERICAL]\n",
            "\t17 : CC [NUMERICAL]\n",
            "\t15 : EH [NUMERICAL]\n",
            "\t15 : BQ [NUMERICAL]\n",
            "\t14 : GL [NUMERICAL]\n",
            "\t14 : DE [NUMERICAL]\n",
            "\t13 : CR [NUMERICAL]\n",
            "\t11 : FL [NUMERICAL]\n",
            "\t10 : EE [NUMERICAL]\n",
            "\t10 : DL [NUMERICAL]\n",
            "\t10 : CU [NUMERICAL]\n",
            "\t9 : EL [NUMERICAL]\n",
            "\t9 : AX [NUMERICAL]\n",
            "\t8 : FE [NUMERICAL]\n",
            "\t8 : EG [NUMERICAL]\n",
            "\t8 : BC [NUMERICAL]\n",
            "\t7 : EU [NUMERICAL]\n",
            "\t7 : DH [NUMERICAL]\n",
            "\t7 : DA [NUMERICAL]\n",
            "\t7 : CH [NUMERICAL]\n",
            "\t7 : BR [NUMERICAL]\n",
            "\t6 : EB [NUMERICAL]\n",
            "\t6 : DY [NUMERICAL]\n",
            "\t6 : CS [NUMERICAL]\n",
            "\t6 : CD_ [NUMERICAL]\n",
            "\t6 : AH [NUMERICAL]\n",
            "\t5 : FI [NUMERICAL]\n",
            "\t5 : DN [NUMERICAL]\n",
            "\t5 : AF [NUMERICAL]\n",
            "\t4 : GH [NUMERICAL]\n",
            "\t4 : CL [NUMERICAL]\n",
            "\t3 : EP [NUMERICAL]\n",
            "\t3 : DV [NUMERICAL]\n",
            "\t3 : DI [NUMERICAL]\n",
            "\t3 : DF [NUMERICAL]\n",
            "\t3 : AM [NUMERICAL]\n",
            "\t2 : FS [NUMERICAL]\n",
            "\t2 : CB [NUMERICAL]\n",
            "\t2 : BP [NUMERICAL]\n",
            "\t2 : AY [NUMERICAL]\n",
            "\t1 : GI [NUMERICAL]\n",
            "\t1 : GE [NUMERICAL]\n",
            "\t1 : GB [NUMERICAL]\n",
            "\t1 : FD_ [NUMERICAL]\n",
            "\t1 : FC [NUMERICAL]\n",
            "\t1 : CF [NUMERICAL]\n",
            "\t1 : BN [NUMERICAL]\n",
            "\t1 : AR [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t40 : DU [NUMERICAL]\n",
            "\t26 : AB [NUMERICAL]\n",
            "\t18 : FR [NUMERICAL]\n",
            "\t17 : CC [NUMERICAL]\n",
            "\t15 : EH [NUMERICAL]\n",
            "\t15 : BQ [NUMERICAL]\n",
            "\t14 : GL [NUMERICAL]\n",
            "\t14 : DE [NUMERICAL]\n",
            "\t13 : CR [NUMERICAL]\n",
            "\t11 : FL [NUMERICAL]\n",
            "\t10 : EE [NUMERICAL]\n",
            "\t10 : DL [NUMERICAL]\n",
            "\t10 : CU [NUMERICAL]\n",
            "\t9 : EL [NUMERICAL]\n",
            "\t9 : AX [NUMERICAL]\n",
            "\t8 : FE [NUMERICAL]\n",
            "\t8 : EG [NUMERICAL]\n",
            "\t8 : BC [NUMERICAL]\n",
            "\t7 : EU [NUMERICAL]\n",
            "\t7 : DH [NUMERICAL]\n",
            "\t7 : DA [NUMERICAL]\n",
            "\t7 : CH [NUMERICAL]\n",
            "\t7 : BR [NUMERICAL]\n",
            "\t6 : EB [NUMERICAL]\n",
            "\t6 : DY [NUMERICAL]\n",
            "\t6 : CS [NUMERICAL]\n",
            "\t6 : CD_ [NUMERICAL]\n",
            "\t6 : AH [NUMERICAL]\n",
            "\t5 : FI [NUMERICAL]\n",
            "\t5 : DN [NUMERICAL]\n",
            "\t5 : AF [NUMERICAL]\n",
            "\t4 : GH [NUMERICAL]\n",
            "\t4 : CL [NUMERICAL]\n",
            "\t3 : EP [NUMERICAL]\n",
            "\t3 : DV [NUMERICAL]\n",
            "\t3 : DI [NUMERICAL]\n",
            "\t3 : DF [NUMERICAL]\n",
            "\t3 : AM [NUMERICAL]\n",
            "\t2 : FS [NUMERICAL]\n",
            "\t2 : CB [NUMERICAL]\n",
            "\t2 : BP [NUMERICAL]\n",
            "\t2 : AY [NUMERICAL]\n",
            "\t1 : GI [NUMERICAL]\n",
            "\t1 : GE [NUMERICAL]\n",
            "\t1 : GB [NUMERICAL]\n",
            "\t1 : FD_ [NUMERICAL]\n",
            "\t1 : FC [NUMERICAL]\n",
            "\t1 : CF [NUMERICAL]\n",
            "\t1 : BN [NUMERICAL]\n",
            "\t1 : AR [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t40 : DU [NUMERICAL]\n",
            "\t26 : AB [NUMERICAL]\n",
            "\t18 : FR [NUMERICAL]\n",
            "\t17 : CC [NUMERICAL]\n",
            "\t15 : EH [NUMERICAL]\n",
            "\t15 : BQ [NUMERICAL]\n",
            "\t14 : GL [NUMERICAL]\n",
            "\t14 : DE [NUMERICAL]\n",
            "\t13 : CR [NUMERICAL]\n",
            "\t11 : FL [NUMERICAL]\n",
            "\t10 : EE [NUMERICAL]\n",
            "\t10 : DL [NUMERICAL]\n",
            "\t10 : CU [NUMERICAL]\n",
            "\t9 : EL [NUMERICAL]\n",
            "\t9 : AX [NUMERICAL]\n",
            "\t8 : FE [NUMERICAL]\n",
            "\t8 : EG [NUMERICAL]\n",
            "\t8 : BC [NUMERICAL]\n",
            "\t7 : EU [NUMERICAL]\n",
            "\t7 : DH [NUMERICAL]\n",
            "\t7 : DA [NUMERICAL]\n",
            "\t7 : CH [NUMERICAL]\n",
            "\t7 : BR [NUMERICAL]\n",
            "\t6 : EB [NUMERICAL]\n",
            "\t6 : DY [NUMERICAL]\n",
            "\t6 : CS [NUMERICAL]\n",
            "\t6 : CD_ [NUMERICAL]\n",
            "\t6 : AH [NUMERICAL]\n",
            "\t5 : FI [NUMERICAL]\n",
            "\t5 : DN [NUMERICAL]\n",
            "\t5 : AF [NUMERICAL]\n",
            "\t4 : GH [NUMERICAL]\n",
            "\t4 : CL [NUMERICAL]\n",
            "\t3 : EP [NUMERICAL]\n",
            "\t3 : DV [NUMERICAL]\n",
            "\t3 : DI [NUMERICAL]\n",
            "\t3 : DF [NUMERICAL]\n",
            "\t3 : AM [NUMERICAL]\n",
            "\t2 : FS [NUMERICAL]\n",
            "\t2 : CB [NUMERICAL]\n",
            "\t2 : BP [NUMERICAL]\n",
            "\t2 : AY [NUMERICAL]\n",
            "\t1 : GI [NUMERICAL]\n",
            "\t1 : GE [NUMERICAL]\n",
            "\t1 : GB [NUMERICAL]\n",
            "\t1 : FD_ [NUMERICAL]\n",
            "\t1 : FC [NUMERICAL]\n",
            "\t1 : CF [NUMERICAL]\n",
            "\t1 : BN [NUMERICAL]\n",
            "\t1 : AR [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t40 : DU [NUMERICAL]\n",
            "\t26 : AB [NUMERICAL]\n",
            "\t18 : FR [NUMERICAL]\n",
            "\t17 : CC [NUMERICAL]\n",
            "\t15 : EH [NUMERICAL]\n",
            "\t15 : BQ [NUMERICAL]\n",
            "\t14 : GL [NUMERICAL]\n",
            "\t14 : DE [NUMERICAL]\n",
            "\t13 : CR [NUMERICAL]\n",
            "\t11 : FL [NUMERICAL]\n",
            "\t10 : EE [NUMERICAL]\n",
            "\t10 : DL [NUMERICAL]\n",
            "\t10 : CU [NUMERICAL]\n",
            "\t9 : EL [NUMERICAL]\n",
            "\t9 : AX [NUMERICAL]\n",
            "\t8 : FE [NUMERICAL]\n",
            "\t8 : EG [NUMERICAL]\n",
            "\t8 : BC [NUMERICAL]\n",
            "\t7 : EU [NUMERICAL]\n",
            "\t7 : DH [NUMERICAL]\n",
            "\t7 : DA [NUMERICAL]\n",
            "\t7 : CH [NUMERICAL]\n",
            "\t7 : BR [NUMERICAL]\n",
            "\t6 : EB [NUMERICAL]\n",
            "\t6 : DY [NUMERICAL]\n",
            "\t6 : CS [NUMERICAL]\n",
            "\t6 : CD_ [NUMERICAL]\n",
            "\t6 : AH [NUMERICAL]\n",
            "\t5 : FI [NUMERICAL]\n",
            "\t5 : DN [NUMERICAL]\n",
            "\t5 : AF [NUMERICAL]\n",
            "\t4 : GH [NUMERICAL]\n",
            "\t4 : CL [NUMERICAL]\n",
            "\t3 : EP [NUMERICAL]\n",
            "\t3 : DV [NUMERICAL]\n",
            "\t3 : DI [NUMERICAL]\n",
            "\t3 : DF [NUMERICAL]\n",
            "\t3 : AM [NUMERICAL]\n",
            "\t2 : FS [NUMERICAL]\n",
            "\t2 : CB [NUMERICAL]\n",
            "\t2 : BP [NUMERICAL]\n",
            "\t2 : AY [NUMERICAL]\n",
            "\t1 : GI [NUMERICAL]\n",
            "\t1 : GE [NUMERICAL]\n",
            "\t1 : GB [NUMERICAL]\n",
            "\t1 : FD_ [NUMERICAL]\n",
            "\t1 : FC [NUMERICAL]\n",
            "\t1 : CF [NUMERICAL]\n",
            "\t1 : BN [NUMERICAL]\n",
            "\t1 : AR [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t130 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t374 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t374 : HigherCondition\n",
            "\n",
            "Training logs:\n",
            "Number of iteration to final model: 130\n",
            "\tIter:1 train-loss:0.854250 valid-loss:0.833704  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:2 train-loss:0.794809 valid-loss:0.797670  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:3 train-loss:0.749318 valid-loss:0.762543  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:4 train-loss:0.714176 valid-loss:0.743258  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:5 train-loss:0.680427 valid-loss:0.713925  train-accuracy:0.823214 valid-accuracy:0.842105\n",
            "\tIter:6 train-loss:0.649487 valid-loss:0.682638  train-accuracy:0.851786 valid-accuracy:0.859649\n",
            "\tIter:16 train-loss:0.466892 valid-loss:0.596601  train-accuracy:0.933929 valid-accuracy:0.877193\n",
            "\tIter:26 train-loss:0.377456 valid-loss:0.590215  train-accuracy:0.953571 valid-accuracy:0.859649\n",
            "\tIter:36 train-loss:0.315939 valid-loss:0.565237  train-accuracy:0.964286 valid-accuracy:0.859649\n",
            "\tIter:46 train-loss:0.263968 valid-loss:0.557920  train-accuracy:0.969643 valid-accuracy:0.859649\n",
            "\tIter:56 train-loss:0.229165 valid-loss:0.541964  train-accuracy:0.975000 valid-accuracy:0.859649\n",
            "\tIter:66 train-loss:0.202645 valid-loss:0.523548  train-accuracy:0.978571 valid-accuracy:0.859649\n",
            "\tIter:76 train-loss:0.175469 valid-loss:0.528234  train-accuracy:0.982143 valid-accuracy:0.859649\n",
            "\tIter:86 train-loss:0.150488 valid-loss:0.504039  train-accuracy:0.989286 valid-accuracy:0.859649\n",
            "\tIter:96 train-loss:0.130010 valid-loss:0.490322  train-accuracy:0.992857 valid-accuracy:0.859649\n",
            "\tIter:106 train-loss:0.114961 valid-loss:0.487844  train-accuracy:0.994643 valid-accuracy:0.859649\n",
            "\tIter:116 train-loss:0.102846 valid-loss:0.475622  train-accuracy:0.996429 valid-accuracy:0.859649\n",
            "\tIter:126 train-loss:0.089917 valid-loss:0.469268  train-accuracy:0.996429 valid-accuracy:0.877193\n",
            "\tIter:136 train-loss:0.081898 valid-loss:0.464954  train-accuracy:0.996429 valid-accuracy:0.859649\n",
            "\tIter:146 train-loss:0.072915 valid-loss:0.479952  train-accuracy:0.998214 valid-accuracy:0.859649\n",
            "\tIter:156 train-loss:0.064986 valid-loss:0.476820  train-accuracy:0.998214 valid-accuracy:0.859649\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train the model"
      ],
      "metadata": {
        "id": "z8zaWGPTlDU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of ids for the creation of oof dataframe.\n",
        "ID_LIST = clean_train.index\n",
        "\n",
        "# Create a dataframe of required size with zero values.\n",
        "oof = pd.DataFrame(data=np.zeros((len(ID_LIST),1)), index=ID_LIST)\n",
        "\n",
        "# Create an empty dictionary to store the models trained for each fold.\n",
        "models = {}\n",
        "\n",
        "# Create empty dict to save metircs for the models trained for each fold.\n",
        "accuracy = {}\n",
        "cross_entropy = {}\n",
        "\n",
        "# Save the name of the label column to a variable.\n",
        "label = \"Class\"\n",
        "\n",
        "# Creates a GroupKFold with 5 splits\n",
        "kf = KFold(n_splits=5)"
      ],
      "metadata": {
        "id": "ctmUQYwZnjA9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataset_df, class_weight):\n",
        "  # Create subplots for accuracy and loss\n",
        "  fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Accuracy\", \"Loss\"))\n",
        "\n",
        "  # Loop through each fold\n",
        "  for i, (train_index, valid_index) in enumerate(kf.split(X=dataset_df)):\n",
        "    print('##### Fold',i+1)\n",
        "\n",
        "    # Fetch values corresponding to the index\n",
        "    train_df = dataset_df.iloc[train_index]\n",
        "    valid_df = dataset_df.iloc[valid_index]\n",
        "    valid_ids = valid_df.index.values\n",
        "\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df, label=label)\n",
        "\n",
        "    # Define the model and metrics\n",
        "    model = tfdf.keras.GradientBoostedTreesModel(max_depth=3, num_trees=700)\n",
        "    model.compile(metrics=[\"accuracy\", \"binary_crossentropy\"])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x=train_ds, class_weight=class_weight)\n",
        "\n",
        "    # Store the model\n",
        "    models[f\"fold_{i+1}\"] = model\n",
        "\n",
        "    # Predict OOF value for validation data\n",
        "    predict = model.predict(x=valid_ds)\n",
        "\n",
        "    # Store the predictions in oof dataframe\n",
        "    oof.loc[valid_ids, 0] = predict.flatten()\n",
        "\n",
        "    # Evaluate and store the metrics in respective dicts\n",
        "    evaluation = model.evaluate(x=valid_ds,return_dict=True)\n",
        "    accuracy[f\"fold_{i+1}\"] = evaluation[\"accuracy\"]\n",
        "    cross_entropy[f\"fold_{i+1}\"]= evaluation[\"binary_crossentropy\"]\n",
        "\n",
        "    # Update accuracy plot\n",
        "    fold_accuracy = evaluation[\"accuracy\"]\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[fold_accuracy], mode='markers+lines', name=f'Accuracy Fold {i+1}'), row=1, col=1)\n",
        "\n",
        "    # Update loss plot\n",
        "    fold_loss = evaluation[\"binary_crossentropy\"]\n",
        "    fig.add_trace(go.Scatter(x=[i+1], y=[fold_loss], mode='markers+lines', name=f'Loss Fold {i+1}'), row=2, col=1)\n",
        "\n",
        "  average_loss = 0\n",
        "  average_acc = 0\n",
        "\n",
        "  for _model in  models:\n",
        "      average_loss += cross_entropy[_model]\n",
        "      average_acc += accuracy[_model]\n",
        "      print(f\"\\n{_model}: acc: {accuracy[_model]:.4f} loss: {cross_entropy[_model]:.4f}\")\n",
        "\n",
        "  print(f\"\\nAverage accuracy: {average_acc/5:.4f}  Average loss: {average_loss/5:.4f}\")\n",
        "\n",
        "  # Set titles for both subplots\n",
        "  fig.update_layout(title=\"Accuracy and Loss per Fold\")\n",
        "  fig.update_xaxes(title_text=\"Fold\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"Fold\", row=2, col=1)\n",
        "  fig.update_yaxes(title_text=\"Value\", row=2, col=1)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = train_model(clean_train, class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLNK9jpTVFyQ",
        "outputId": "eebd890c-1424-4ae1-e956-b2c02fca6300"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Fold 1\n",
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpx8uu19dx as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:01.212303. Found 493 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.778368\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x79e11c439900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 196ms/step\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.0000e+00 - accuracy: 0.9597 - binary_crossentropy: 0.1458\n",
            "##### Fold 2\n",
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp9h8af1th as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:01.709731. Found 493 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:01.646286\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x79e11c248c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled.\n",
            "1/1 [==============================] - 0s 418ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 0.8790 - binary_crossentropy: 0.2557\n",
            "##### Fold 3\n",
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpio9yv92d as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x79e142a35b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:02.739321. Found 494 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:01.972276\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x79e11c1003a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 472ms/step\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0000e+00 - accuracy: 0.9268 - binary_crossentropy: 0.2221\n",
            "##### Fold 4\n",
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpb46t_awz as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x79e142a35b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.854643. Found 494 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.252497\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x79e0edbac700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x79e0edbac820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 291ms/step - loss: 0.0000e+00 - accuracy: 0.9187 - binary_crossentropy: 0.2841\n",
            "##### Fold 5\n",
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpkvmk0bnb as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.816685. Found 494 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.576389\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 133ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x79e0d93c7d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 312ms/step - loss: 0.0000e+00 - accuracy: 0.9512 - binary_crossentropy: 0.1557\n",
            "\n",
            "fold_1: acc: 0.9597 loss: 0.1458\n",
            "\n",
            "fold_2: acc: 0.8790 loss: 0.2557\n",
            "\n",
            "fold_3: acc: 0.9268 loss: 0.2221\n",
            "\n",
            "fold_4: acc: 0.9187 loss: 0.2841\n",
            "\n",
            "fold_5: acc: 0.9512 loss: 0.1557\n",
            "\n",
            "Average accuracy: 0.9271  Average loss: 0.2127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"6048ca2e-af51-43b2-975c-4d6331de42e6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6048ca2e-af51-43b2-975c-4d6331de42e6\")) {                    Plotly.newPlot(                        \"6048ca2e-af51-43b2-975c-4d6331de42e6\",                        [{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 1\",\"x\":[1],\"y\":[0.9596773982048035],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 1\",\"x\":[1],\"y\":[0.14578063786029816],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 2\",\"x\":[2],\"y\":[0.8790322542190552],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 2\",\"x\":[2],\"y\":[0.25568893551826477],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 3\",\"x\":[3],\"y\":[0.9268292784690857],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 3\",\"x\":[3],\"y\":[0.2221246212720871],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 4\",\"x\":[4],\"y\":[0.9186992049217224],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 4\",\"x\":[4],\"y\":[0.2840743064880371],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"markers+lines\",\"name\":\"Accuracy Fold 5\",\"x\":[5],\"y\":[0.9512194991111755],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"markers+lines\",\"name\":\"Loss Fold 5\",\"x\":[5],\"y\":[0.15571792423725128],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Fold\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Fold\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"Value\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Accuracy and Loss per Fold\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6048ca2e-af51-43b2-975c-4d6331de42e6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save the Model\n"
      ],
      "metadata": {
        "id": "r9RuWAtX70CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/ICR_Project/ICR_model.keras', save_format=\"keras\")"
      ],
      "metadata": {
        "id": "q4Zn0D6M7yh-"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}